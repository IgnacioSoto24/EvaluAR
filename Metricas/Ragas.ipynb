{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe4f2de-7df5-44e8-a242-ff736990159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\bakug\\anaconda3\\lib\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 15.9 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\bakug\\anaconda3\\python.exe -m pip install -U pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\bakug\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\bakug\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\bakug\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\bakug\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\bakug\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\bakug\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.7-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.58)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.5.3)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_ollama-0.3.7-py3-none-any.whl (24 kB)\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-ollama\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.27\n",
      "    Uninstalling langsmith-0.3.27:\n",
      "      Successfully uninstalled langsmith-0.3.27\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.58\n",
      "    Uninstalling langchain-core-0.3.58:\n",
      "      Successfully uninstalled langchain-core-0.3.58\n",
      "Successfully installed langchain-core-0.3.75 langchain-ollama-0.3.7 langsmith-0.3.45\n",
      "Collecting ragas@ git+https://github.com/explodinggradients/ragas.git\n",
      "  Cloning https://github.com/explodinggradients/ragas.git to c:\\users\\bakug\\appdata\\local\\temp\\pip-install-65nec9g8\\ragas_63a6d3ff38954d2bb20407537a361369\n",
      "  Resolved https://github.com/explodinggradients/ragas.git to commit 4f29e76e2e59bf2e4119421ebfdbf64ecbbe90e4\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (1.26.4)\n",
      "Requirement already satisfied: datasets>=4.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.9.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (5.6.3)\n",
      "Requirement already satisfied: typer in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.9.0)\n",
      "Requirement already satisfied: rich in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (13.7.1)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (1.104.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (4.66.5)\n",
      "Requirement already satisfied: instructor in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (1.10.0)\n",
      "Requirement already satisfied: gitpython in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (3.1.43)\n",
      "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (10.4.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.25)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.75)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.23)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic>=2.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic>=2.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic>=2.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from tqdm->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from gitpython->ragas@ git+https://github.com/explodinggradients/ragas.git) (4.0.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.10.5)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.1.4)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (9.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from rich->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from rich->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.15.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from typer->ragas@ git+https://github.com/explodinggradients/ragas.git) (8.1.7)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.3.45)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.0.34)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-core->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from tiktoken->ragas@ git+https://github.com/explodinggradients/ragas.git) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.9.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas@ git+https://github.com/explodinggradients/ragas.git) (4.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas@ git+https://github.com/explodinggradients/ragas.git) (0.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas@ git+https://github.com/explodinggradients/ragas.git) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas@ git+https://github.com/explodinggradients/ragas.git) (1.0.0)\n",
      "Building wheels for collected packages: ragas\n",
      "  Building wheel for ragas (pyproject.toml): started\n",
      "  Building wheel for ragas (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ragas: filename=ragas-0.3.3.dev54+g4f29e76e2-py3-none-any.whl size=281464 sha256=83e58531d4019e5b7be1671a53ef6d8bf7ea499b05b79b7e608984397ca5a1f2\n",
      "  Stored in directory: C:\\Users\\bakug\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-r5ldoa9r\\wheels\\35\\47\\07\\f6a75fda84027caf19217a034146a4b76f4be682b2765d0e12\n",
      "Successfully built ragas\n",
      "Installing collected packages: ragas\n",
      "  Attempting uninstall: ragas\n",
      "    Found existing installation: ragas 0.3.3.dev52+ge82110535\n",
      "    Uninstalling ragas-0.3.3.dev52+ge82110535:\n",
      "      Successfully uninstalled ragas-0.3.3.dev52+ge82110535\n",
      "Successfully installed ragas-0.3.3.dev54+g4f29e76e2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/explodinggradients/ragas.git 'C:\\Users\\bakug\\AppData\\Local\\Temp\\pip-install-65nec9g8\\ragas_63a6d3ff38954d2bb20407537a361369'\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install datasets pandas nest_asyncio sentence-transformers faiss-cpu\n",
    "!pip install langchain langchain-community langchain-ollama\n",
    "!pip install \"ragas @ git+https://github.com/explodinggradients/ragas.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df1e1ee-b78d-41c2-883e-ca491bee5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_relevancy,\n",
    "    faithfulness\n",
    ")\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac692d4-0996-4521-85dc-d48b83ceb17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\bakug\\anaconda3\\lib\\site-packages (0.3.25)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain-community in c:\\users\\bakug\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\bakug\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\bakug\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: ragas in c:\\users\\bakug\\anaconda3\\lib\\site-packages (0.3.3.dev54+g4f29e76e2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: datasets>=4.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: typer in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: rich in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (13.7.1)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (1.104.2)\n",
      "Requirement already satisfied: instructor in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (1.10.0)\n",
      "Requirement already satisfied: gitpython in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (3.1.43)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from ragas) (0.3.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from datasets>=4.0.0->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=4.0.0->ragas) (2024.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from gitpython->ragas) (4.0.7)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from instructor->ragas) (0.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from rich->ragas) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from rich->ragas) (2.15.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from typer->ragas) (8.1.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bakug\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community sentence-transformers faiss-cpu ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35c7a24-abce-4a50-b357-a9485fb941b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM listo con Ollama: llama3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bakug\\AppData\\Local\\Temp\\ipykernel_18456\\1745582752.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings listos: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_MODEL = \"llama3\"\n",
    "\n",
    "try:\n",
    "    chat_llm = ChatOllama(model=OLLAMA_MODEL, temperature=0.1)\n",
    "    print(f\"✅ LLM listo con Ollama: {OLLAMA_MODEL}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"No pude conectar con Ollama. Verifica:\\n\"\n",
    "        \"1) 'ollama serve' corriendo\\n\"\n",
    "        \"2) 'ollama pull llama3' ejecutado\\n\"\n",
    "        f\"Detalle: {e}\"\n",
    "    )\n",
    "\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "print(f\"✅ Embeddings listos: {EMBEDDING_MODEL}\")\n",
    "\n",
    "llm_wrapper = LangchainLLMWrapper(chat_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb83f6f4-6fe5-45a3-b93a-0555d76a2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos cargados: 876\n",
      "✅ FAISS construido e inicializado (k=3).\n"
     ]
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train[:1%]\")  # ~875 ejemplos aprox.\n",
    "print(f\"Ejemplos cargados: {len(squad)}\")\n",
    "\n",
    "contexts = list({item[\"context\"] for item in squad})\n",
    "docs = [Document(page_content=c) for c in contexts]\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"✅ FAISS construido e inicializado (k=3).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac96ae53-9555-40b6-b5b7-82027dbc19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = dedent(\"\"\"\n",
    "Eres un tutor pedagógico. Responde SOLO usando el CONTEXTO provisto.\n",
    "Si el contexto no es suficiente, responde con: \"No puedo responder con la información proporcionada.\"\n",
    "Responde en español, de forma breve y clara.\n",
    "\"\"\").strip()\n",
    "\n",
    "def generar_respuesta_rag(pregunta: str):\n",
    "    retrieved_docs = retriever.get_relevant_documents(pregunta)\n",
    "    ctx_texts = [d.page_content for d in retrieved_docs]\n",
    "    contexto = \"\\n\\n---\\n\\n\".join(ctx_texts)\n",
    "\n",
    "    mensaje_sistema = (\"Sistema: \" + SYSTEM_INSTRUCTIONS)\n",
    "    mensaje_usuario  = f\"Contexto:\\n{contexto}\\n\\nPregunta del estudiante: {pregunta}\\nRespuesta:\"\n",
    "\n",
    "    resp = chat_llm.invoke([{\"role\": \"system\", \"content\": mensaje_sistema},\n",
    "                            {\"role\": \"user\", \"content\": mensaje_usuario}])\n",
    "\n",
    "    respuesta = resp.content if hasattr(resp, \"content\") else str(resp)\n",
    "    return respuesta, ctx_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a823b64-1af3-4163-8f2e-45dba131f376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✅ Ejemplo de respuestas generadas (3 tipos)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tipo</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What percentage of Egyptians polled support de...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What percentage of Eg...</td>\n",
       "      <td>84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>Ann Arbor ranks 1st among what goods sold?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: Ann Arbor ranks 1st a...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>In developing countries, who makes most of the...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: In developing countri...</td>\n",
       "      <td>the executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>Who impressed Xavier by taking notes in church?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: Who impressed Xavier ...</td>\n",
       "      <td>Anjiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What represents elements of the fundamental gr...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What represents eleme...</td>\n",
       "      <td>loops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What is the population of the Commonwealth?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What is the populatio...</td>\n",
       "      <td>2.2 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What was Eisenhower's title after Germany's su...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What was Eisenhower's...</td>\n",
       "      <td>Military Governor of the U.S. Occupation Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>These regions were occupied by who?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: These regions were oc...</td>\n",
       "      <td>the brown men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What could be done by understanding how the di...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What could be done by...</td>\n",
       "      <td>resources could be targeted to the communities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>What kind of ants are symbolic among the Austr...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Respuesta simulada para: What kind of ants are...</td>\n",
       "      <td>honey ants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>Who blew up the HMS Jasper?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>París es la capital de Italia.</td>\n",
       "      <td>The Cossacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>What pigment was made by soaking copper plates...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>La fotosíntesis ocurre en el estómago humano.</td>\n",
       "      <td>verdigris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>In what decade did the LEAA conduct their inve...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>La Revolución Francesa fue en 1999.</td>\n",
       "      <td>1970s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>Who designed the COMPASS navigation system?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>El agua hierve a -50 grados.</td>\n",
       "      <td>Sun Jiadong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>With whom does the primary responsibility for ...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>La Tierra tiene dos lunas.</td>\n",
       "      <td>House Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>Children under what age often cannot comprehen...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>El oxígeno es un metal pesado.</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>What offshoots of polychaetes are unsegmented?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>La Segunda Guerra Mundial terminó en 1800.</td>\n",
       "      <td>echiurans and sipunculan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>What has a strong influence over all aspect of...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>Los mamíferos ponen huevos siempre.</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>What does the of toxin Clostridium tetani rele...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>El Pacífico es un desierto.</td>\n",
       "      <td>paralyzes muscles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>The Church of England uses what term that is h...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No hay continentes en el planeta.</td>\n",
       "      <td>tituli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>Where studio hosts the live final rounds on Am...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>CBS Television City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>During what years did Austria rule Palermo?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>1720 and 1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>What was the population of the state in 2015?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>1,032,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>Where did the degrees of Freemasonry derived f...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>the three grades</td>\n",
       "      <td>the three grades of medieval craft guilds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>What neighbours south Jiangsu to the north?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>Zhejiang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>How many restaurants does the island have?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>over 70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>What is the largest athletic organisation in t...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>German Football Federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>What was the first country to be able to buy t...</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>What is the arid measurement in Namibia?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>150 to 300 mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>When was Two Stars for Peace published?</td>\n",
       "      <td>[Contexto simulado]</td>\n",
       "      <td>No dispongo de toda la información, pero está ...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tipo                                           question  \\\n",
       "0     Correcta  What percentage of Egyptians polled support de...   \n",
       "1     Correcta         Ann Arbor ranks 1st among what goods sold?   \n",
       "2     Correcta  In developing countries, who makes most of the...   \n",
       "3     Correcta    Who impressed Xavier by taking notes in church?   \n",
       "4     Correcta  What represents elements of the fundamental gr...   \n",
       "5     Correcta        What is the population of the Commonwealth?   \n",
       "6     Correcta  What was Eisenhower's title after Germany's su...   \n",
       "7     Correcta                These regions were occupied by who?   \n",
       "8     Correcta  What could be done by understanding how the di...   \n",
       "9     Correcta  What kind of ants are symbolic among the Austr...   \n",
       "10  Incorrecta                        Who blew up the HMS Jasper?   \n",
       "11  Incorrecta  What pigment was made by soaking copper plates...   \n",
       "12  Incorrecta  In what decade did the LEAA conduct their inve...   \n",
       "13  Incorrecta        Who designed the COMPASS navigation system?   \n",
       "14  Incorrecta  With whom does the primary responsibility for ...   \n",
       "15  Incorrecta  Children under what age often cannot comprehen...   \n",
       "16  Incorrecta     What offshoots of polychaetes are unsegmented?   \n",
       "17  Incorrecta  What has a strong influence over all aspect of...   \n",
       "18  Incorrecta  What does the of toxin Clostridium tetani rele...   \n",
       "19  Incorrecta  The Church of England uses what term that is h...   \n",
       "20     Parcial  Where studio hosts the live final rounds on Am...   \n",
       "21     Parcial        During what years did Austria rule Palermo?   \n",
       "22     Parcial      What was the population of the state in 2015?   \n",
       "23     Parcial  Where did the degrees of Freemasonry derived f...   \n",
       "24     Parcial        What neighbours south Jiangsu to the north?   \n",
       "25     Parcial         How many restaurants does the island have?   \n",
       "26     Parcial  What is the largest athletic organisation in t...   \n",
       "27     Parcial  What was the first country to be able to buy t...   \n",
       "28     Parcial           What is the arid measurement in Namibia?   \n",
       "29     Parcial            When was Two Stars for Peace published?   \n",
       "\n",
       "               contexts                                             answer  \\\n",
       "0   [Contexto simulado]  Respuesta simulada para: What percentage of Eg...   \n",
       "1   [Contexto simulado]  Respuesta simulada para: Ann Arbor ranks 1st a...   \n",
       "2   [Contexto simulado]  Respuesta simulada para: In developing countri...   \n",
       "3   [Contexto simulado]  Respuesta simulada para: Who impressed Xavier ...   \n",
       "4   [Contexto simulado]  Respuesta simulada para: What represents eleme...   \n",
       "5   [Contexto simulado]  Respuesta simulada para: What is the populatio...   \n",
       "6   [Contexto simulado]  Respuesta simulada para: What was Eisenhower's...   \n",
       "7   [Contexto simulado]  Respuesta simulada para: These regions were oc...   \n",
       "8   [Contexto simulado]  Respuesta simulada para: What could be done by...   \n",
       "9   [Contexto simulado]  Respuesta simulada para: What kind of ants are...   \n",
       "10  [Contexto simulado]                     París es la capital de Italia.   \n",
       "11  [Contexto simulado]      La fotosíntesis ocurre en el estómago humano.   \n",
       "12  [Contexto simulado]                La Revolución Francesa fue en 1999.   \n",
       "13  [Contexto simulado]                       El agua hierve a -50 grados.   \n",
       "14  [Contexto simulado]                         La Tierra tiene dos lunas.   \n",
       "15  [Contexto simulado]                     El oxígeno es un metal pesado.   \n",
       "16  [Contexto simulado]         La Segunda Guerra Mundial terminó en 1800.   \n",
       "17  [Contexto simulado]                Los mamíferos ponen huevos siempre.   \n",
       "18  [Contexto simulado]                        El Pacífico es un desierto.   \n",
       "19  [Contexto simulado]                  No hay continentes en el planeta.   \n",
       "20  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "21  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "22  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "23  [Contexto simulado]                                   the three grades   \n",
       "24  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "25  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "26  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "27  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "28  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "29  [Contexto simulado]  No dispongo de toda la información, pero está ...   \n",
       "\n",
       "                                         ground_truth  \n",
       "0                                                 84%  \n",
       "1                                               books  \n",
       "2                                       the executive  \n",
       "3                                              Anjiro  \n",
       "4                                               loops  \n",
       "5                                         2.2 billion  \n",
       "6       Military Governor of the U.S. Occupation Zone  \n",
       "7                                       the brown men  \n",
       "8   resources could be targeted to the communities...  \n",
       "9                                          honey ants  \n",
       "10                                       The Cossacks  \n",
       "11                                          verdigris  \n",
       "12                                              1970s  \n",
       "13                                        Sun Jiadong  \n",
       "14                                       House Master  \n",
       "15                                               nine  \n",
       "16                           echiurans and sipunculan  \n",
       "17                                           Religion  \n",
       "18                                  paralyzes muscles  \n",
       "19                                             tituli  \n",
       "20                                CBS Television City  \n",
       "21                                      1720 and 1734  \n",
       "22                                          1,032,949  \n",
       "23          the three grades of medieval craft guilds  \n",
       "24                                           Zhejiang  \n",
       "25                                            over 70  \n",
       "26                         German Football Federation  \n",
       "27                                              Japan  \n",
       "28                                      150 to 300 mm  \n",
       "29                                               2003  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ Conteo por tipo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Cantidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Correcta</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Incorrecta</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parcial</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tipo  Cantidad\n",
       "0    Correcta        10\n",
       "1  Incorrecta        10\n",
       "2     Parcial        10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "import random\n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"train\")\n",
    "muestra = squad.shuffle(seed=42).select(range(30))\n",
    "\n",
    "muestra_dict = muestra.to_dict()\n",
    "muestra_filas = [\n",
    "    {\n",
    "        \"question\": muestra_dict[\"question\"][i],\n",
    "        \"context\": muestra_dict[\"context\"][i],\n",
    "        \"answers\": muestra_dict[\"answers\"][i]\n",
    "    }\n",
    "    for i in range(len(muestra_dict[\"question\"]))\n",
    "]\n",
    "\n",
    "def primera_respuesta_verdadera(item):\n",
    "    answers = item[\"answers\"][\"text\"]\n",
    "    return answers[0] if answers else \"\"\n",
    "\n",
    "def generar_respuesta_rag(pregunta):\n",
    "    return f\"Respuesta simulada para: {pregunta}\", [\"Contexto simulado\"]\n",
    "\n",
    "# A) RESPUESTAS CORRECTAS\n",
    "rows_correctas = []\n",
    "for item in muestra_filas[:10]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    gen, ctxs = generar_respuesta_rag(q)\n",
    "    rows_correctas.append({\n",
    "        \"Tipo\": \"Correcta\",\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": gen,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "# B) RESPUESTAS INCORRECTAS\n",
    "respuestas_erroneas = [\n",
    "    \"París es la capital de Italia.\",\n",
    "    \"La fotosíntesis ocurre en el estómago humano.\",\n",
    "    \"La Revolución Francesa fue en 1999.\",\n",
    "    \"El agua hierve a -50 grados.\",\n",
    "    \"La Tierra tiene dos lunas.\",\n",
    "    \"El oxígeno es un metal pesado.\",\n",
    "    \"La Segunda Guerra Mundial terminó en 1800.\",\n",
    "    \"Los mamíferos ponen huevos siempre.\",\n",
    "    \"El Pacífico es un desierto.\",\n",
    "    \"No hay continentes en el planeta.\"\n",
    "]\n",
    "\n",
    "rows_incorrectas = []\n",
    "for i, item in enumerate(muestra_filas[10:20]):\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_incorrectas.append({\n",
    "        \"Tipo\": \"Incorrecta\",\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": respuestas_erroneas[i % len(respuestas_erroneas)],\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "# C) RESPUESTAS PARCIALES\n",
    "rows_parciales = []\n",
    "for item in muestra_filas[20:30]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    if len(gt.split()) > 6:\n",
    "        parcial = \" \".join(gt.split()[: max(3, len(gt.split()) // 3)])\n",
    "    else:\n",
    "        parcial = \"No dispongo de toda la información, pero está relacionado con el contexto.\"\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_parciales.append({\n",
    "        \"Tipo\": \"Parcial\",\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": parcial,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "df_correctas = pd.DataFrame(rows_correctas)\n",
    "df_incorrectas = pd.DataFrame(rows_incorrectas)\n",
    "df_parciales = pd.DataFrame(rows_parciales)\n",
    "\n",
    "df_total = pd.concat([df_correctas, df_incorrectas, df_parciales], ignore_index=True)\n",
    "\n",
    "display(Markdown(\"### ✅ Ejemplo de respuestas generadas (3 tipos)\"))\n",
    "display(df_total.head(30))\n",
    "\n",
    "conteo_tipos = df_total[\"Tipo\"].value_counts().reset_index()\n",
    "conteo_tipos.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "display(Markdown(\"### ✅ Conteo por tipo\"))\n",
    "display(conteo_tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f94233-c18d-4d0a-a58d-e88c5d9567f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ✅ Análisis inicial de tipos de respuesta"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **Distribución de tipos de respuesta**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tipo\n",
       "Correcta      10\n",
       "Incorrecta    10\n",
       "Parcial       10\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Gráfico\u001b[39;00m\n\u001b[0;32m     20\u001b[0m conteo\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m], figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribución de respuestas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTipo de respuesta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCantidad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAHACAYAAADUeNDTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxfklEQVR4nO3deVxU5f///+cIsiWgqCgmi/uOlktft4w007TN3pVZZqalpRmamlaK+El5a+WHzJLsnUuf0rTStN6lkaWlaakYlktGbmS55AIqgcKc3x/9nFvj4AINjjPX4367ze3mXOeac70GjsxzzrnOOTbLsiwBAACjlPN0AQAA4PIjAAAAYCACAAAABiIAAABgIAIAAAAGIgAAAGAgAgAAAAYiAAAAYCACAAAABiIAAD5kxIgRuvrqq5Wdne3pUgBc4QgA8Ki5c+fKZrM5HkFBQapevboSEhKUkpKiQ4cOubxmwoQJstlsJRonLy9PEyZM0KpVq0r0uuLGiouLU8+ePUu0Hne42PtesmSJZs+erU8//VTR0dGXpSabzaYJEyZclrFMsW3bNk2YMEF79uzxdCnwcQQAXBHmzJmjdevWKT09Xa+++qpatGihKVOmqFGjRvr888+d+g4cOFDr1q0r0frz8vKUnJxc4gBQmrHKyoVq2bVrlwYNGqQPPvhA8fHxl7kyuNO2bduUnJxMAECZ8/d0AYAkNW3aVK1atXI8v+uuuzR8+HB16NBBvXr10s8//6xq1apJkmrWrKmaNWuWaT15eXkKCQm5LGNdqgvVUrt27WL3lng7y7KUn5+v4OBgT5cC+Bz2AOCKFRMTo5deekknTpzQ66+/7mgvblf4F198oRtuuEGVK1dWcHCwYmJidNdddykvL0979uxR1apVJUnJycmOww0PPfSQ0/oyMjL0r3/9S5UqVVKdOnXOO9ZZS5YsUXx8vIKCglS7dm1Nnz7dafnZwxvnfpNbtWqVbDaby96I5cuXq3PnzgoPD1dISIgaNWqklJSUC75vu92uqVOnqmHDhgoMDFRkZKQefPBB/frrr079brjhBjVt2lQbNmxQx44dFRISotq1a+vf//637HZ7se/v73Jzc/XII4+ocuXKqlChgrp166adO3cW2/fnn39Wnz59FBkZqcDAQDVq1EivvvrqRceQ/jqkMHToUKWlpalRo0YKDAzUvHnzLnm9drtdzz//vBo0aKDg4GBVrFhR8fHxevnll11+jps3b1avXr0UFham8PBwPfDAAzp8+LBLPcUd4oiLi3NsP2cdOHBAgwYNUs2aNRUQEKBatWopOTlZhYWFTv1mzpyp5s2bq0KFCgoNDVXDhg31zDPPSPprm7n77rslSQkJCY5tde7cuZKk9PR03X777apZs6aCgoJUt25dDRo0SH/88YfTGIcPH9ajjz6q6OhoBQYGqmrVqmrfvr3L3jSYjT0AuKLdcsst8vPz01dffXXePnv27FGPHj3UsWNHzZ49WxUrVtT+/fu1fPlynT59WlFRUVq+fLm6deumAQMGaODAgZLkCAVn9erVS71799bgwYN16tSpC9b1/fffKzExURMmTFD16tX1zjvv6Mknn9Tp06c1cuTIEr/PN998U4888og6deqktLQ0RUZGaufOnfrxxx8v+LrHHntMs2bN0tChQ9WzZ0/t2bNH48aN06pVq5SRkaEqVao4+h44cED333+/nnrqKSUlJWnJkiUaO3asatSooQcffPC8Y1iWpTvuuEPffPONxo8fr9atW2vt2rXq3r27S99t27apXbt2jvBWvXp1rVixQsOGDdMff/yhpKSki/4sPvzwQ3399dcaP368qlevrsjIyEte79SpUzVhwgQ999xzuv7663XmzBnt2LFDx48fdxnnzjvv1D333KPBgwdr69atGjdunLZt26Zvv/1W5cuXv2idf3fgwAG1adNG5cqV0/jx41WnTh2tW7dOzz//vPbs2aM5c+ZIkt599109/vjjeuKJJ/Tiiy+qXLlyysrK0rZt2yRJPXr00OTJk/XMM8/o1Vdf1bXXXitJjkD6yy+/qG3btho4cKDCw8O1Z88eTZs2TR06dNAPP/zgqLtv377KyMjQpEmTVL9+fR0/flwZGRk6cuRIid4XfJwFeNCcOXMsSdaGDRvO26datWpWo0aNHM+TkpKsv2+677//viXJ+v7778+7jsOHD1uSrKSkJJdlZ9c3fvz48y77u9jYWMtms7mMd9NNN1lhYWHWqVOnnN7b7t27nfp9+eWXliTryy+/tCzLsk6cOGGFhYVZHTp0sOx2+3nfw7m1bN++3ZJkPf744079vv32W0uS9cwzzzjaOnXqZEmyvv32W6e+jRs3tm6++ebzjmlZlvXpp59akqyXX37ZqX3SpEkuP9Obb77ZqlmzppWTk+PUd+jQoVZQUJB19OjRC44lyQoPD3fpd6nr7dmzp9WiRYsLjnH25zh8+HCn9nfeeceSZL399ttO9RS3zcTGxlr9+vVzPB80aJBVoUIFa+/evU79XnzxRUuStXXrVke9FStWvGB97733ntP2cT52u906c+aMtXfvXkuStXTpUseyChUqWImJiRd8PcAhAFzxLMu64PIWLVooICBAjz76qObNm6ddu3aVapy77rrrkvs2adJEzZs3d2rr06ePcnNzlZGRUaJxv/nmG+Xm5urxxx8v0dkNX375pSS57Ipu06aNGjVqpJUrVzq1V69eXW3atHFqi4+P1969ey9pnPvvv9+pvU+fPk7P8/PztXLlSt15550KCQlRYWGh43HLLbcoPz9f69evv+j7uvHGG1WpUqVSrbdNmzbKzMzU448/rhUrVig3N/e845z7fu655x75+/s73m9JfPzxx0pISFCNGjWc6ju7l2T16tWO+o4fP6777rtPS5cuddl1fzGHDh3S4MGDFR0dLX9/f5UvX16xsbGSpO3btzv6tWnTRnPnztXzzz+v9evX68yZMyV+T/B9BABc0U6dOqUjR46oRo0a5+1Tp04dff7554qMjNSQIUNUp04d1alTx+m476WIioq65L7Vq1c/b1tJd7OePe5c0smGZ8cpru4aNWq41FG5cmWXfoGBgfrzzz8vOo6/v7/L68/9GRw5ckSFhYV65ZVXVL58eafHLbfcIkmX9IF37vspyXrHjh2rF198UevXr1f37t1VuXJlde7cWRs3bnQZ59z6z77H0uwmP3jwoD766COX+po0aeJUX9++fTV79mzt3btXd911lyIjI3XdddcpPT39omPY7XZ17dpVixcv1ujRo7Vy5Up99913jvDz99/jwoUL1a9fP/3nP/9R27ZtFRERoQcffFAHDhwo8XuD72IOAK5o//3vf1VUVKQbbrjhgv06duyojh07qqioSBs3btQrr7yixMREVatWTb17976ksUry7bu4P6Rn285+UAYFBUmSCgoKnPqd+yF4di7CuRP3LubsOL///rtLePjtt9+cjv//E5UrV1ZhYaGOHDniFALO/RlUqlRJfn5+6tu3r4YMGVLsumrVqnXR8c79PZRkvf7+/hoxYoRGjBih48eP6/PPP9czzzyjm2++WdnZ2QoJCXGq/+qrr3Y8L+49BgYGuvz+JNeQV6VKFcXHx2vSpEnF1vf3ANu/f3/1799fp06d0ldffaWkpCT17NlTO3fudHybL86PP/6ozMxMzZ07V/369XO0Z2VlufStUqWKUlNTlZqaqn379mnZsmUaM2aMDh06pOXLl593DJiFAIAr1r59+zRy5EiFh4dr0KBBl/QaPz8/XXfddWrYsKHeeecdZWRkqHfv3goMDJSki37bvVRbt25VZmam02GA+fPnKzQ01DFxKy4uTpK0ZcsWNWjQwNFv2bJlTutq166dwsPDlZaWpt69e19yELnxxhslSW+//bZat27taN+wYYO2b9+uZ599tlTv7VwJCQmaOnWq3nnnHQ0bNszRPn/+fKd+ISEhSkhI0ObNmxUfH6+AgAC3jF/a9VasWFH/+te/tH//fiUmJmrPnj1q3LixY/k777yjli1bOp4vWrRIhYWFTmEzLi5OW7ZscVrvF198oZMnTzq19ezZU5988onq1KnjdPjiQq666ip1795dp0+f1h133KGtW7cqNjb2vNvq2e3i7PKz/n6GTHFiYmI0dOhQrVy5UmvXrr2k2mAGAgCuCD/++KPjuOmhQ4f09ddfa86cOfLz89OSJUtcZuz/XVpamr744gv16NFDMTExys/P1+zZsyVJXbp0kSSFhoYqNjZWS5cuVefOnRUREaEqVao4PqRLqkaNGrrttts0YcIERUVF6e2331Z6erqmTJni+JbZunVrNWjQQCNHjlRhYaEqVaqkJUuWaM2aNU7rqlChgl566SUNHDhQXbp00SOPPKJq1aopKytLmZmZmjFjRrE1NGjQQI8++qheeeUVlStXTt27d3ecBRAdHa3hw4eX6r2dq2vXrrr++us1evRonTp1Sq1atdLatWv1f//3fy59X375ZXXo0EEdO3bUY489pri4OJ04cUJZWVn66KOP9MUXX5Sqhktd76233uq4pkTVqlW1d+9epaamKjY2VvXq1XNa5+LFi+Xv76+bbrrJcRZA8+bNdc899zj69O3bV+PGjdP48ePVqVMnbdu2TTNmzFB4eLjTuiZOnKj09HS1a9dOw4YNU4MGDZSfn689e/bok08+UVpammrWrKlHHnlEwcHBat++vaKionTgwAGlpKQoPDzcEeKaNm0qSZo1a5ZCQ0MVFBSkWrVqqWHDhqpTp47GjBkjy7IUERGhjz76yOXwQU5OjhISEtSnTx81bNhQoaGh2rBhg5YvX65evXqV6ucPH+XpWYgw29mZ8mcfAQEBVmRkpNWpUydr8uTJ1qFDh1xec+5s+HXr1ll33nmnFRsbawUGBlqVK1e2OnXqZC1btszpdZ9//rl1zTXXWIGBgZYkxyzus+s7fPjwRceyrL9mgPfo0cN6//33rSZNmlgBAQFWXFycNW3aNJfX79y50+ratasVFhZmVa1a1XriiSes//73v8XO8v7kk0+sTp06WVdddZUVEhJiNW7c2JoyZcoFaykqKrKmTJli1a9f3ypfvrxVpUoV64EHHrCys7Od+nXq1Mlq0qSJS339+vWzYmNjXdrPdfz4cevhhx+2KlasaIWEhFg33XSTtWPHjmJnye/evdt6+OGHrauvvtoqX768VbVqVatdu3bW888/f9FxJFlDhgwpdtmlrPell16y2rVrZ1WpUsUKCAiwYmJirAEDBlh79uxx9Dn7c9y0aZN16623WhUqVLBCQ0Ot++67zzp48KDTmAUFBdbo0aOt6OhoKzg42OrUqZP1/fffu5wFYFl/nWkybNgwq1atWlb58uWtiIgIq2XLltazzz5rnTx50rIsy5o3b56VkJBgVatWzQoICLBq1Khh3XPPPdaWLVuc1pWammrVqlXL8vPzsyRZc+bMsSzLsrZt22bddNNNVmhoqFWpUiXr7rvvtvbt2+f0e8jPz7cGDx5sxcfHW2FhYVZwcLDVoEEDKykpyXGGCmBZlmWzrItMsQYAHzJhwgQlJyfr8OHDbpsnAXgjzgIAAMBABAAAAAzEIQAAAAzEHgAAAAxEAAAAwEAEAAAADHTFXQjIbrfrt99+U2hoaIkuzQoAgOksy9KJEydUo0YNlSt34e/4V1wA+O233xQdHe3pMgAA8FrZ2dkXvcHYFRcAQkNDJf1VfFhYmIerAQDAe+Tm5io6OtrxWXohV1wAOLvbPywsjAAAAEApXMohdCYBAgBgIAIAAAAGIgAAAGAgAgAAAAYiAAAAYCACAAAABiIAAABgIAIAAAAGKnEA+Oqrr3TrrbeqRo0astls+vDDD52WW5alCRMmqEaNGgoODtYNN9ygrVu3uqteAADgBiUOAKdOnVLz5s01Y8aMYpdPnTpV06ZN04wZM7RhwwZVr15dN910k06cOPGPiwUAAO5R4ksBd+/eXd27dy92mWVZSk1N1bPPPqtevXpJkubNm6dq1app/vz5GjRokMtrCgoKVFBQ4Hiem5tb0pIAAEAJufVeALt379aBAwfUtWtXR1tgYKA6deqkb775ptgAkJKSouTkZHeWUaZsydyiuDSsJMvTJXgfboddOhbbWonNZ1srlT7eva25dRLggQMHJEnVqlVzaq9WrZpj2bnGjh2rnJwcxyM7O9udJQEAgGKUyd0Az70LkWVZ570zUWBgoAIDA8uiDAAAcB5u3QNQvXp1SXL5tn/o0CGXvQIAAMBz3BoAatWqperVqys9Pd3Rdvr0aa1evVrt2rVz51AAAOAfKPEhgJMnTyorK8vxfPfu3fr+++8VERGhmJgYJSYmavLkyapXr57q1aunyZMnKyQkRH369HFr4QAAoPRKHAA2btyohIQEx/MRI0ZIkvr166e5c+dq9OjR+vPPP/X444/r2LFjuu666/TZZ58pNDTUfVUDAIB/xGZZV9Y5M7m5uQoPD1dOTo7CwsI8XY4LTgMsHU4DLAVOAyydK+tPmnfgNMDSuQJPAyzJZyj3AgAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBAbg8AhYWFeu6551SrVi0FBwerdu3amjhxoux2u7uHAgAApeTv7hVOmTJFaWlpmjdvnpo0aaKNGzeqf//+Cg8P15NPPunu4QAAQCm4PQCsW7dOt99+u3r06CFJiouL04IFC7Rx40Z3DwUAAErJ7YcAOnTooJUrV2rnzp2SpMzMTK1Zs0a33HJLsf0LCgqUm5vr9AAAAGXL7XsAnn76aeXk5Khhw4by8/NTUVGRJk2apPvuu6/Y/ikpKUpOTnZ3GQAA4ALcvgdg4cKFevvttzV//nxlZGRo3rx5evHFFzVv3rxi+48dO1Y5OTmOR3Z2trtLAgAA53D7HoBRo0ZpzJgx6t27tySpWbNm2rt3r1JSUtSvXz+X/oGBgQoMDHR3GQAA4ALcvgcgLy9P5co5r9bPz4/TAAEAuIK4fQ/ArbfeqkmTJikmJkZNmjTR5s2bNW3aND388MPuHgoAAJSS2wPAK6+8onHjxunxxx/XoUOHVKNGDQ0aNEjjx49391AAAKCU3B4AQkNDlZqaqtTUVHevGgAAuAn3AgAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxUJgFg//79euCBB1S5cmWFhISoRYsW2rRpU1kMBQAASsHf3Ss8duyY2rdvr4SEBH366aeKjIzUL7/8oooVK7p7KAAAUEpuDwBTpkxRdHS05syZ42iLi4tz9zAAAOAfcPshgGXLlqlVq1a6++67FRkZqWuuuUZvvPHGefsXFBQoNzfX6QEAAMqW2wPArl27NHPmTNWrV08rVqzQ4MGDNWzYML311lvF9k9JSVF4eLjjER0d7e6SAADAOWyWZVnuXGFAQIBatWqlb775xtE2bNgwbdiwQevWrXPpX1BQoIKCAsfz3NxcRUdHKycnR2FhYe4szS1syTZPl+CVrCS3bmZmsLGtlYp7/6SZYT7bWqn0ufK2tdzcXIWHh1/SZ6jb9wBERUWpcePGTm2NGjXSvn37iu0fGBiosLAwpwcAAChbbg8A7du3108//eTUtnPnTsXGxrp7KAAAUEpuDwDDhw/X+vXrNXnyZGVlZWn+/PmaNWuWhgwZ4u6hAABAKbk9ALRu3VpLlizRggUL1LRpU/3P//yPUlNTdf/997t7KAAAUEpuvw6AJPXs2VM9e/Ysi1UDAAA34F4AAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgQgAAAAYiAAAAICBCAAAABiIAAAAgIEIAAAAGIgAAACAgco8AKSkpMhmsykxMbGshwIAAJeoTAPAhg0bNGvWLMXHx5flMAAAoITKLACcPHlS999/v9544w1VqlTpvP0KCgqUm5vr9AAAAGWrzALAkCFD1KNHD3Xp0uWC/VJSUhQeHu54REdHl1VJAADg/1cmAeDdd99VRkaGUlJSLtp37NixysnJcTyys7PLoiQAAPA3/u5eYXZ2tp588kl99tlnCgoKumj/wMBABQYGursMAABwAW4PAJs2bdKhQ4fUsmVLR1tRUZG++uorzZgxQwUFBfLz83P3sAAAoATcHgA6d+6sH374wamtf//+atiwoZ5++mk+/AEAuAK4PQCEhoaqadOmTm1XXXWVKleu7NIOAAA8gysBAgBgILfvASjOqlWrLscwAADgErEHAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAO5PQCkpKSodevWCg0NVWRkpO644w799NNP7h4GAAD8A24PAKtXr9aQIUO0fv16paenq7CwUF27dtWpU6fcPRQAACglf3evcPny5U7P58yZo8jISG3atEnXX3+9u4cDAACl4PYAcK6cnBxJUkRERLHLCwoKVFBQ4Hiem5tb1iUBAGC8Mp0EaFmWRowYoQ4dOqhp06bF9klJSVF4eLjjER0dXZYlAQAAlXEAGDp0qLZs2aIFCxact8/YsWOVk5PjeGRnZ5dlSQAAQGV4COCJJ57QsmXL9NVXX6lmzZrn7RcYGKjAwMCyKgMAABTD7QHAsiw98cQTWrJkiVatWqVatWq5ewgAAPAPuT0ADBkyRPPnz9fSpUsVGhqqAwcOSJLCw8MVHBzs7uEAAEApuH0OwMyZM5WTk6MbbrhBUVFRjsfChQvdPRQAACilMjkEAAAArmzcCwAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADBQmQWA1157TbVq1VJQUJBatmypr7/+uqyGAgAAJVQmAWDhwoVKTEzUs88+q82bN6tjx47q3r279u3bVxbDAQCAEiqTADBt2jQNGDBAAwcOVKNGjZSamqro6GjNnDmzLIYDAAAl5O/uFZ4+fVqbNm3SmDFjnNq7du2qb775xqV/QUGBCgoKHM9zcnIkSbm5ue4uzT3yPV2Ad7pif5/wPWxrJZfn6QK81BW4rZ39W2tZ1kX7uj0A/PHHHyoqKlK1atWc2qtVq6YDBw649E9JSVFycrJLe3R0tLtLgweF/zvc0yXAFOFsa7hMHrlyt7UTJ04o/CL/F9weAM6y2WxOzy3LcmmTpLFjx2rEiBGO53a7XUePHlXlypWL7Y/i5ebmKjo6WtnZ2QoLC/N0OfBhbGu4XNjWSs6yLJ04cUI1atS4aF+3B4AqVarIz8/P5dv+oUOHXPYKSFJgYKACAwOd2ipWrOjusowRFhbGfxRcFmxruFzY1krmYt/8z3L7JMCAgAC1bNlS6enpTu3p6elq166du4cDAAClUCaHAEaMGKG+ffuqVatWatu2rWbNmqV9+/Zp8ODBZTEcAAAooTIJAPfee6+OHDmiiRMn6vfff1fTpk31ySefKDY2tiyGg/46lJKUlORyOAVwN7Y1XC5sa2XLZl3KuQIAAMCncC8AAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAADEQAAADAQGV2LwBcPnl5edq3b59Onz7t1B4fH++higAAVzoCgBc7fPiw+vfvr08//bTY5UVFRZe5Iviy999/X4sWLSo2bGZkZHioKviCXr16XXLfxYsXl2ElZuEQgBdLTEzUsWPHtH79egUHB2v58uWaN2+e6tWrp2XLlnm6PPiQ6dOnq3///oqMjNTmzZvVpk0bVa5cWbt27VL37t09XR68XHh4+CU/4D5cCdCLRUVFaenSpWrTpo3CwsK0ceNG1a9fX8uWLdPUqVO1Zs0aT5cIH9GwYUMlJSXpvvvuU2hoqDIzM1W7dm2NHz9eR48e1YwZMzxdIoASYg+AFzt16pQiIyMlSRERETp8+LAkqVmzZuyShVvt27fPcTfP4OBgnThxQpLUt29fLViwwJOlASgl5gB4sQYNGuinn35SXFycWrRooddff11xcXFKS0tTVFSUp8uDD6levbqOHDmi2NhYxcbGav369WrevLl2794tdiLC3ZhvcnmwB8CLJSYm6vfff5ckJSUlafny5YqJidH06dM1efJkD1cHX3LjjTfqo48+kiQNGDBAw4cP10033aR7771Xd955p4ergy9hvsnlwxwAH5KXl6cdO3YoJiZGVapU8XQ58CF2u112u13+/n/tNFy0aJHWrFmjunXravDgwQoICPBwhfAVzDe5fAgAXmzixIkaOXKkQkJCnNr//PNPvfDCCxo/fryHKoOv2bdvn6Kjo2Wz2ZzaLctSdna2YmJiPFQZfE1ISIi2b9+u2NhYRUZGKj09Xc2bN9fPP/+s//f//p+OHDni6RJ9BocAvFhycrJOnjzp0p6Xl6fk5GQPVARfVatWLcck0787evSoatWq5YGK4KvOzjeR5JhvIon5JmWAAODFLMty+UYmSZmZmYqIiPBARfBV59vWTp48qaCgIA9UBF/FfJPLh7MAvFClSpVks9lks9lUv359pz/MRUVFOnnypAYPHuzBCuErRowYIUmy2WwaN26c0+GmoqIiffvtt2rRooWHqoMvmjVrlux2uyRp8ODBioiI0Jo1a3Trrbfyd83NmAPghebNmyfLsvTwww8rNTXV6epYAQEBiouLU9u2bT1YIXxFQkKCJGn16tVq27at02S/s9vayJEjVa9ePU+VCKCUCABebPXq1Wrfvr1jZjZQVvr376+XX35ZYWFhni4FPmjLli1q2rSpypUrpy1btlywLzc5cx8CgBf75JNP5Ofnp5tvvtmpfcWKFbLb7ZwzC7fJyclRUVGRy9ySo0ePyt/fn2CAf6RcuXI6cOCAIiMjVa5cOdlstmIn/NlsNm5y5kZMAvRiY8aMKfY/g2VZGjNmjAcqgq/q3bu33n33XZf2RYsWqXfv3h6oCL5k9+7dqlq1quPfu3bt0u7du10eu3bt8nClvoU9AF4sODhY27dvV1xcnFP7nj171KRJE506dcozhcHnREREaO3atWrUqJFT+44dO9S+fXvOzQa8EHsAvFh4eHixiTgrK0tXXXWVByqCryooKFBhYaFL+5kzZ/Tnn396oCL4qpSUFM2ePdulffbs2ZoyZYoHKvJdBAAvdttttykxMVG//PKLoy0rK0tPPfWUbrvtNg9WBl/TunVrzZo1y6U9LS1NLVu29EBF8FWvv/66GjZs6NLepEkTpaWleaAi38UhAC+Wk5Ojbt26aePGjapZs6Yk6ddff1XHjh21ePFiVaxY0bMFwmesXbtWXbp0UevWrdW5c2dJ0sqVK7VhwwZ99tln6tixo4crhK8ICgrS9u3bXa4wuWvXLjVu3Fj5+fkeqsz3cP6YFwsPD9c333yj9PR0ZWZmKjg4WPHx8br++us9XRp8TPv27bVu3TpNnTpVixYtcmxrb775JtcAgFtFR0dr7dq1LgFg7dq1qlGjhoeq8k3sAfAR+fn5CgwMLPZyrQDgLaZMmaIXXnhBL7zwgm688UZJf+1tGj16tJ566imNHTvWwxX6DgKAF7Pb7Zo0aZLS0tJ08OBB7dy5U7Vr19a4ceMUFxenAQMGeLpE+JBffvlFc+bM0a5du5SamqrIyEgtX75c0dHRatKkiafLg484exrz9OnTdfr0aUl/HRZ4+umnucOpmzEJ0Is9//zzmjt3rqZOnep0idZmzZrpP//5jwcrg69ZvXq1mjVrpm+//VYffPCB4y6UW7ZsUVJSkoerg68oKirSV199paefflqHDx/W+vXrlZmZqaNHj/LhXwbYA+DF6tatq9dff12dO3dWaGioMjMzVbt2be3YsUNt27bVsWPHPF0ifETbtm119913a8SIEU7b2oYNG3THHXdo//79ni4RPuJ8kwDhfuwB8GL79+9X3bp1XdrtdrvOnDnjgYrgq3744Ydib8VatWpVLgIEt2rWrBlX/LtMCABerEmTJvr6669d2t977z1dc801HqgIvqpixYr6/fffXdo3b96sq6++2gMVwVdNmjRJI0eO1Mcff6zff/9dubm5Tg+4D6cBerGkpCT17dtX+/fvl91u1+LFi/XTTz/prbfe0scff+zp8uBD+vTpo6efflrvvfeebDab7Ha71q5dq5EjR+rBBx/0dHnwId26dZP014XO/n5Wk2VZ3AzIzZgD4OVWrFihyZMna9OmTbLb7br22ms1fvx4de3a1dOlwYecOXNGDz30kN59911ZliV/f38VFRWpT58+mjt3rvz8/DxdInzE6tWrL7i8U6dOl6kS30cA8FKFhYWaNGmSHn74YUVHR3u6HPgwy7K0b98+Va1aVQcOHFBGRobsdruuueYaLgIEeDECgBerUKGCfvzxR5e7AQLuZLfbFRQUpK1bt/KBj8smLy9P+/btc1wL4Kz4+HgPVeR7mAPgxbp06aJVq1bpoYce8nQp8GHlypVTvXr1dOTIEQIAytzhw4fVv39/ffrpp8UuZw6A+xAAvFj37t01duxY/fjjj2rZsqXLLYC5IyDcZerUqRo1apRmzpyppk2beroc+LDExEQdO3ZM69evV0JCgpYsWaKDBw/q+eef10svveTp8nwKhwC8WLly5z+Lk9mycKdKlSopLy9PhYWFCggIUHBwsNPyo0ePeqgy+JqoqCgtXbpUbdq0UVhYmDZu3Kj69etr2bJlmjp1qtasWePpEn0GewC8mN1u93QJMERqaqqnS4AhTp06pcjISElSRESEDh8+rPr166tZs2bKyMjwcHW+hQDgpQoLCxUUFKTvv/+eXbIoU2fOnNGqVas0btw41a5d29PlwMc1aNBAP/30k+Li4tSiRQu9/vrriouLU1pamqKiojxdnk/hSoBeyt/fX7GxsezmR5krX768lixZ4ukyYIjExETHVSeTkpK0fPlyxcTEaPr06Zo8ebKHq/MtzAHwYnPmzNF7772nt99+WxEREZ4uBz6sf//+atasmUaMGOHpUuCj8vLyNGrUKH344Yc6c+aMunTpounTpyskJEQ7duxQTEyMqlSp4ukyfQoBwItdc801ysrK0pkzZxQbG+tyFgDHy+AukyZN0osvvqjOnTsXe8bJsGHDPFQZfMWoUaP02muv6f7771dwcLDmz5+vG264Qe+9956nS/NZBAAvlpycfMHl3Kcd7nKhW7PabDbu3oZ/rE6dOpo0aZJ69+4tSfruu+/Uvn175efnc6npMkIAAAB4XEBAgHbv3u10d8ng4GDt3LmTy52XEc4C8AGbNm3S9u3bZbPZ1LhxY24FjDJ19jvD3+/UBvxTRUVFCggIcGrz9/dXYWGhhyryfQQAL3bo0CH17t1bq1atUsWKFWVZlnJycpSQkKB3331XVatW9XSJ8CFvvfWWXnjhBf3888+SpPr162vUqFHq27evhyuDL7AsSw899JACAwMdbfn5+Ro8eLDTnJPFixd7ojyfRADwYk888YRyc3O1detWNWrUSJK0bds29evXT8OGDdOCBQs8XCF8xbRp0zRu3DgNHTpU7du3l2VZWrt2rQYPHqw//vhDw4cP93SJ8HL9+vVzaXvggQc8UIk5mAPgxcLDw/X555+rdevWTu3fffedunbtquPHj3umMPicWrVqKTk5WQ8++KBT+7x58zRhwgTt3r3bQ5UBKC0uBOTF7Ha7ypcv79Jevnx5LhMMt/r999/Vrl07l/Z27do5LtoCwLsQALzYjTfeqCeffFK//fabo23//v0aPny4Onfu7MHK4Gvq1q2rRYsWubQvXLiQWwQDXopDAF4sOztbt99+u3788UdFR0fLZrNp3759atasmZYuXaqaNWt6ukT4iA8++ED33nuvunTpovbt28tms2nNmjVauXKlFi1apDvvvNPTJQIoIQKAD0hPT9eOHTtkWZYaN26sLl26eLok+KBNmzbpf//3f7V9+3bHtvbUU09x2ingpQgAXuiLL77Q0KFDtX79eoWFhTkty8nJUbt27ZSWlqaOHTt6qEIAwJWOOQBeKDU1VY888ojLh7/015kBgwYN0rRp0zxQGXzVJ598ohUrVri0r1ixQp9++qkHKgLwTxEAvFBmZqa6det23uVdu3bVpk2bLmNF8HVjxowp9tbTlmVpzJgxHqgIwD9FAPBCBw8eLPb0v7P8/f11+PDhy1gRfN3PP/+sxo0bu7Q3bNhQWVlZHqgIwD9FAPBCV199tX744YfzLt+yZYuioqIuY0XwdeHh4cXe8S8rK8vl1sAAvAMBwAvdcsstGj9+vPLz812W/fnnn0pKSlLPnj09UBl81W233abExET98ssvjrasrCw99dRTuu222zxYGYDS4iwAL3Tw4EFde+218vPz09ChQ9WgQQPZbDZt375dr776qoqKipSRkaFq1ap5ulT4iJycHHXr1k0bN250XF/i119/VceOHbV48WJVrFjRswUCKDECgJfau3evHnvsMa1YscLp9qw333yzXnvtNcXFxXm2QPgcy7KUnp6uzMxMBQcHKz4+Xtdff72nywJQSgQAL3fs2DFlZWXJsizVq1dPlSpV8nRJAAAvQAAAcElWrlyplStX6tChQy43m5o9e7aHqgJQWv6eLgDAlS85OVkTJ05Uq1atFBUVJZvN5umSAPxD7AEAcFFRUVGaOnWq+vbt6+lSALgJpwECuKjTp0+rXbt2ni4DgBsRAABc1MCBAzV//nxPlwHAjZgDAOCi8vPzNWvWLH3++eeKj493uRQ1N58CvA9zAABcVEJCwgWXf/nll5epEgDuQgAAAMBAHAIAcF69evW6aB+bzaYPPvjgMlQDwJ0IAADOKzw83NMlACgjHAIAAMBAnAYIAICBCAAAABiIAAAAgIEIAAAAGIgAAOC8JkyYoBYtWni6DABlgLMAAENd7Ja+/fr104wZM1RQUKDKlStfpqoAXC4EAMBQBw4ccPx74cKFGj9+vH766SdHW3BwMNcBAHwYhwAAQ1WvXt3xCA8Pl81mc2k79xDAQw89pDvuuEPJycmKjIxUWFiYBg0apNOnTzv6FBQUaNiwYYqMjFRQUJA6dOigDRs2eOAdArgQAgCAElm5cqW2b9+uL7/8UgsWLNCSJUuUnJzsWD569Gh98MEHmjdvnjIyMlS3bl3dfPPNOnr0qAerBnAuAgCAEgkICNDs2bPVpEkT9ejRQxMnTtT06dNlt9t16tQpzZw5Uy+88IK6d++uxo0b64033lBwcLDefPNNT5cO4G+4FwCAEmnevLlCQkIcz9u2bauTJ08qOztbOTk5OnPmjNq3b+9YXr58ebVp00bbt2/3RLkAzoM9AADcwmaz6eyc4nPPMLAs66JnHQC4vAgAAEokMzNTf/75p+P5+vXrVaFCBdWsWVN169ZVQECA1qxZ41h+5swZbdy4UY0aNfJEuQDOg0MAAErk9OnTGjBggJ577jnt3btXSUlJGjp0qMqVK6errrpKjz32mEaNGqWIiAjFxMRo6tSpysvL04ABAzxdOoC/IQAAKJHOnTurXr16uv7661VQUKDevXtrwoQJjuX//ve/Zbfb1bdvX504cUKtWrXSihUrVKlSJc8VDcAFFwICcMkeeughHT9+XB9++KGnSwHwDzEHAAAAAxEAAAAwEIcAAAAwEHsAAAAwEAEAAAADEQAAADAQAQAAAAMRAAAAMBABAAAAAxEAAAAwEAEAAAAD/X9TqQ7AloCSFgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## ✅ Análisis inicial de tipos de respuesta\"))\n",
    "\n",
    "df_correctas[\"Tipo\"] = \"Correcta\"\n",
    "df_incorrectas[\"Tipo\"] = \"Incorrecta\"\n",
    "df_parciales[\"Tipo\"] = \"Parcial\"\n",
    "\n",
    "df_total = pd.concat([df_correctas, df_incorrectas, df_parciales], ignore_index=True)\n",
    "\n",
    "conteo = df_total[\"Tipo\"].value_counts()\n",
    "display(Markdown(\"### **Distribución de tipos de respuesta**\"))\n",
    "display(conteo)\n",
    "\n",
    "conteo.plot(kind='bar', color=['green', 'red', 'orange'], figsize=(6,4), title=\"Distribución de respuestas\")\n",
    "plt.xlabel(\"Tipo de respuesta\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\"### **Ejemplo de respuestas generadas**\"))\n",
    "display(df_total.head(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924ba38d-b0de-4138-af52-1b6dabda0613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings locales configurados: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bakug\\AppData\\Local\\Temp\\ipykernel_18456\\432619765.py:9: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  embeddings_wrapper = LangchainEmbeddingsWrapper(hf_embeddings)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "embeddings_wrapper = LangchainEmbeddingsWrapper(hf_embeddings)\n",
    "print(f\"✅ Embeddings locales configurados: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229cc9a3-ede5-46ef-b786-b11e8382e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bakug\\AppData\\Local\\Temp\\ipykernel_2548\\2260931149.py:17: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat_llm = ChatOllama(model=OLLAMA_MODEL, temperature=0.1, request_timeout=120)\n",
      "C:\\Users\\bakug\\AppData\\Local\\Temp\\ipykernel_2548\\2260931149.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\bakug\\AppData\\Local\\Temp\\ipykernel_2548\\2260931149.py:22: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  embeddings_wrapper = LangchainEmbeddingsWrapper(embedding_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama y HuggingFace listos\n",
      "Dataset cargado: 9 ejemplos\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# A) RESPUESTAS CORRECTAS\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m squad[:\u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m---> 52\u001b[0m     q \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     53\u001b[0m     gt \u001b[38;5;241m=\u001b[39m primera_respuesta_verdadera(item)\n\u001b[0;32m     54\u001b[0m     gen, ctxs \u001b[38;5;241m=\u001b[39m generar_respuesta_rag(q)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.metrics import ContextPrecision, ContextRecall, Faithfulness, AnswerRelevancy\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.integrations.langchain import LangchainLLMWrapper, LangchainEmbeddingsWrapper\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "OLLAMA_MODEL = \"llama3\"  \n",
    "chat_llm = ChatOllama(model=OLLAMA_MODEL, temperature=0.1, request_timeout=120)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "llm_wrapper = LangchainLLMWrapper(chat_llm)\n",
    "embeddings_wrapper = LangchainEmbeddingsWrapper(embedding_model)\n",
    "\n",
    "print(\"✅ Ollama y HuggingFace listos\")\n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"validation\").shuffle(seed=42).select(range(9))  # Solo 9 ejemplos\n",
    "print(f\"Dataset cargado: {len(squad)} ejemplos\")\n",
    "\n",
    "def primera_respuesta_verdadera(item):\n",
    "    answers = item[\"answers\"][\"text\"]\n",
    "    return answers[0] if answers else \"\"\n",
    "\n",
    "def generar_respuesta_rag(pregunta):\n",
    "    contextos = [\"Contexto simulado: datos relacionados con la pregunta.\"]\n",
    "    respuesta = chat_llm.predict(pregunta)\n",
    "    return respuesta, contextos\n",
    "\n",
    "rows_correctas, rows_incorrectas, rows_parciales = [], [], []\n",
    "\n",
    "# A) RESPUESTAS CORRECTAS\n",
    "for item in squad[:3]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    gen, ctxs = generar_respuesta_rag(q)\n",
    "    rows_correctas.append({\"question\": q, \"contexts\": ctxs, \"answer\": gen, \"ground_truth\": gt})\n",
    "\n",
    "# B) RESPUESTAS INCORRECTAS\n",
    "respuestas_erroneas = [\n",
    "    \"París es la capital de Italia.\",\n",
    "    \"La fotosíntesis ocurre en el estómago humano.\",\n",
    "    \"La Revolución Francesa fue en 1999.\"\n",
    "]\n",
    "for i, item in enumerate(squad[3:6]):\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_incorrectas.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": respuestas_erroneas[i],\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "# C) RESPUESTAS PARCIALES\n",
    "for item in squad[6:9]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    if len(gt.split()) > 6:\n",
    "        parcial = \" \".join(gt.split()[:max(3, len(gt.split()) // 3)])\n",
    "    else:\n",
    "        parcial = \"Respuesta parcial: falta información.\"\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_parciales.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": parcial,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "df_correctas = pd.DataFrame(rows_correctas)\n",
    "df_incorrectas = pd.DataFrame(rows_incorrectas)\n",
    "df_parciales = pd.DataFrame(rows_parciales)\n",
    "\n",
    "display(Markdown(\"### ✅ Conteo por tipo de respuesta\"))\n",
    "print(f\"Correctas: {len(df_correctas)}, Incorrectas: {len(df_incorrectas)}, Parciales: {len(df_parciales)}\")\n",
    "\n",
    "display(Markdown(\"**Ejemplo respuestas correctas:**\"))\n",
    "display(df_correctas.head(1))\n",
    "\n",
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "eval_samples = []\n",
    "for df in [df_correctas, df_incorrectas, df_parciales]:\n",
    "    for _, row in df.iterrows():\n",
    "        eval_samples.append(\n",
    "            SingleTurnSample(\n",
    "                user_input=row[\"question\"],\n",
    "                response=row[\"answer\"],\n",
    "                reference=row[\"ground_truth\"],\n",
    "                retrieved_contexts=row[\"contexts\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "eval_dataset = EvaluationDataset(samples=eval_samples)\n",
    "\n",
    "print(\"## ✅ Calculando métricas...\")\n",
    "resultado = evaluate(\n",
    "    eval_dataset,\n",
    "    metrics=[ContextPrecision(), ContextRecall(), Faithfulness(), AnswerRelevancy()],\n",
    "    llm=llm_wrapper,\n",
    "    embeddings=embeddings_wrapper,\n",
    "    show_progress=False,\n",
    "    max_concurrency=1  \n",
    ")\n",
    "\n",
    "print(\"\\nResultados globales:\")\n",
    "for metric_name, value in resultado.aggregate().items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nResultados por ejemplo:\")\n",
    "for i, r in enumerate(resultado):\n",
    "    print(f\"\\nEjemplo {i+1}:\")\n",
    "    for k, v in r.scores.items():\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "712f6fea-74be-4487-9da9-48d30737650c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m rows_correctas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m muestra[:\u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m---> 29\u001b[0m     q \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m     gt \u001b[38;5;241m=\u001b[39m primera_respuesta_verdadera(item)\n\u001b[0;32m     31\u001b[0m     gen, ctxs \u001b[38;5;241m=\u001b[39m generar_respuesta_rag(q)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "num_muestra = min(30, len(squad))\n",
    "muestra = squad.select(range(num_muestra))\n",
    "\n",
    "def primera_respuesta_verdadera(item):\n",
    "    answers = item[\"answers\"][\"text\"]\n",
    "    return answers[0] if answers else \"\"\n",
    "\n",
    "def generar_respuesta_rag(pregunta):\n",
    "    \"\"\"Simula generación con LLM + RAG.\n",
    "       Devuelve (respuesta_generada, lista_contextos)\"\"\"\n",
    "    return f\"Respuesta generada para: {pregunta}\", [\"Contexto simulado 1\", \"Contexto simulado 2\"]\n",
    "\n",
    "\n",
    "# A) RESPUESTAS CORRECTAS (usamos respuesta simulada + contexto)\n",
    "rows_correctas = []\n",
    "for item in muestra[:3]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    gen, ctxs = generar_respuesta_rag(q)\n",
    "    rows_correctas.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": gen,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "# B) RESPUESTAS INCORRECTAS (fabricamos respuestas absurdas)\n",
    "respuestas_erroneas = [\n",
    "    \"París es la capital de Italia.\",\n",
    "    \"La fotosíntesis ocurre en el estómago humano.\",\n",
    "    \"La Revolución Francesa fue en 1999.\",\n",
    "    \"El agua hierve a -50 grados.\",\n",
    "    \"La Tierra tiene dos lunas.\",\n",
    "    \"El oxígeno es un metal pesado.\",\n",
    "    \"La Segunda Guerra Mundial terminó en 1800.\",\n",
    "    \"Los mamíferos ponen huevos siempre.\",\n",
    "    \"El Pacífico es un desierto.\",\n",
    "    \"No hay continentes en el planeta.\"\n",
    "]\n",
    "\n",
    "rows_incorrectas = []\n",
    "for i, item in enumerate(muestra[3:6]):\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_incorrectas.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": respuestas_erroneas[i % len(respuestas_erroneas)],\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "# C) RESPUESTAS PARCIALES (fragmento del ground truth)\n",
    "rows_parciales = []\n",
    "for item in muestra[6:9]:\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    if len(gt.split()) > 6:\n",
    "        parcial = \" \".join(gt.split()[:max(3, len(gt.split()) // 3)])  # ~1/3 del texto\n",
    "    else:\n",
    "        parcial = \"No dispongo de toda la información, pero está relacionado con el contexto provisto.\"\n",
    "    _, ctxs = generar_respuesta_rag(q)\n",
    "    rows_parciales.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": parcial,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "df_correctas   = pd.DataFrame(rows_correctas)\n",
    "df_incorrectas = pd.DataFrame(rows_incorrectas)\n",
    "df_parciales   = pd.DataFrame(rows_parciales)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"### ✅ Resumen de conjuntos generados\"))\n",
    "print(f\"Respuestas CORRECTAS:   {len(df_correctas)}\")\n",
    "print(f\"Respuestas INCORRECTAS: {len(df_incorrectas)}\")\n",
    "print(f\"Respuestas PARCIALES:   {len(df_parciales)}\")\n",
    "\n",
    "display(Markdown(\"**Ejemplo (correctas):**\"))\n",
    "display(df_correctas.head(2))\n",
    "\n",
    "display(Markdown(\"**Ejemplo (incorrectas):**\"))\n",
    "display(df_incorrectas.head(2))\n",
    "\n",
    "display(Markdown(\"**Ejemplo (parciales):**\"))\n",
    "display(df_parciales.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e238ab3a-c569-4461-bd95-73efab7e0b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "{'id': '572759665951b619008f8884', 'title': 'Private_school', 'context': 'Private schooling in the United States has been debated by educators, lawmakers and parents, since the beginnings of compulsory education in Massachusetts in 1852. The Supreme Court precedent appears to favor educational choice, so long as states may set standards for educational accomplishment. Some of the most relevant Supreme Court case law on this is as follows: Runyon v. McCrary, 427 U.S. 160 (1976); Wisconsin v. Yoder, 406 U.S. 205 (1972); Pierce v. Society of Sisters, 268 U.S. 510 (1925); Meyer v. Nebraska, 262 U.S. 390 (1923).', 'question': 'In what year did Massachusetts first require children to be educated in schools?', 'answers': {'text': ['1852', '1852', '1852'], 'answer_start': [158, 158, 158]}}\n"
     ]
    }
   ],
   "source": [
    "print(type(muestra))\n",
    "print(muestra[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249ca021-dd3b-4bf6-8755-303a964af5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con 10 ejemplos\n",
      "{'id': '56be4db0acb8001400a502ec', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'question': 'Which NFL team represented the AFC at Super Bowl 50?', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n",
      "\n",
      "✅ Ejemplo respuestas CORRECTAS:\n",
      "                                            question  \\\n",
      "0  Which NFL team represented the AFC at Super Bo...   \n",
      "1  Which NFL team represented the NFC at Super Bo...   \n",
      "\n",
      "                                           contexts  \\\n",
      "0  [Este es un contexto simulado para la pregunta.]   \n",
      "1  [Este es un contexto simulado para la pregunta.]   \n",
      "\n",
      "                                              answer       ground_truth  \n",
      "0  Respuesta generada para: Which NFL team repres...     Denver Broncos  \n",
      "1  Respuesta generada para: Which NFL team repres...  Carolina Panthers  \n",
      "\n",
      "✅ Ejemplo respuestas INCORRECTAS:\n",
      "                                            question  \\\n",
      "0  Which NFL team represented the AFC at Super Bo...   \n",
      "1  Which NFL team represented the NFC at Super Bo...   \n",
      "\n",
      "                                           contexts  \\\n",
      "0  [Este es un contexto simulado para la pregunta.]   \n",
      "1  [Este es un contexto simulado para la pregunta.]   \n",
      "\n",
      "                                          answer       ground_truth  \n",
      "0                 París es la capital de Italia.     Denver Broncos  \n",
      "1  La fotosíntesis ocurre en el estómago humano.  Carolina Panthers  \n",
      "\n",
      "✅ Ejemplo respuestas PARCIALES:\n",
      "                                            question  \\\n",
      "0  Which NFL team represented the AFC at Super Bo...   \n",
      "1  Which NFL team represented the NFC at Super Bo...   \n",
      "\n",
      "                                           contexts  \\\n",
      "0  [Este es un contexto simulado para la pregunta.]   \n",
      "1  [Este es un contexto simulado para la pregunta.]   \n",
      "\n",
      "                                              answer       ground_truth  \n",
      "0  No dispongo de toda la información, pero está ...     Denver Broncos  \n",
      "1  No dispongo de toda la información, pero está ...  Carolina Panthers  \n",
      "\n",
      "Conteo por categoría:\n",
      "Correctas: 10\n",
      "Incorrectas: 10\n",
      "Parciales: 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"validation[:10]\")\n",
    "print(f\"Dataset cargado con {len(squad)} ejemplos\")\n",
    "print(squad[0])\n",
    "\n",
    "def primera_respuesta_verdadera(item):\n",
    "    answers = item[\"answers\"][\"text\"]\n",
    "    return answers[0] if answers else \"\"\n",
    "\n",
    "def generar_respuesta_rag(pregunta):\n",
    "    respuesta = f\"Respuesta generada para: {pregunta}\"\n",
    "    contextos = [\"Este es un contexto simulado para la pregunta.\"]\n",
    "    return respuesta, contextos\n",
    "\n",
    "rows_correctas = []\n",
    "rows_incorrectas = []\n",
    "rows_parciales = []\n",
    "\n",
    "respuestas_erroneas = [\n",
    "    \"París es la capital de Italia.\",\n",
    "    \"La fotosíntesis ocurre en el estómago humano.\",\n",
    "    \"La Revolución Francesa fue en 1999.\",\n",
    "    \"El agua hierve a -50 grados.\",\n",
    "    \"La Tierra tiene dos lunas.\",\n",
    "    \"El oxígeno es un metal pesado.\",\n",
    "    \"La Segunda Guerra Mundial terminó en 1800.\",\n",
    "    \"Los mamíferos ponen huevos siempre.\",\n",
    "    \"El Pacífico es un desierto.\",\n",
    "    \"No hay continentes en el planeta.\"\n",
    "]\n",
    "\n",
    "for i, item in enumerate(squad):\n",
    "    q = item[\"question\"]\n",
    "    gt = primera_respuesta_verdadera(item)\n",
    "    gen, ctxs = generar_respuesta_rag(q)\n",
    "\n",
    "    # A) Correcta\n",
    "    rows_correctas.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": gen,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "    # B) Incorrecta\n",
    "    respuesta_incorrecta = respuestas_erroneas[i % len(respuestas_erroneas)]\n",
    "    rows_incorrectas.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": respuesta_incorrecta,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "    # C) Parcial\n",
    "    if len(gt.split()) > 6:\n",
    "        parcial = \" \".join(gt.split()[: max(3, len(gt.split()) // 3)])\n",
    "    else:\n",
    "        parcial = \"No dispongo de toda la información, pero está relacionado.\"\n",
    "    rows_parciales.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": ctxs,\n",
    "        \"answer\": parcial,\n",
    "        \"ground_truth\": gt\n",
    "    })\n",
    "\n",
    "df_correctas = pd.DataFrame(rows_correctas)\n",
    "df_incorrectas = pd.DataFrame(rows_incorrectas)\n",
    "df_parciales = pd.DataFrame(rows_parciales)\n",
    "\n",
    "print(\"\\n✅ Ejemplo respuestas CORRECTAS:\")\n",
    "print(df_correctas.head(2))\n",
    "\n",
    "print(\"\\n✅ Ejemplo respuestas INCORRECTAS:\")\n",
    "print(df_incorrectas.head(2))\n",
    "\n",
    "print(\"\\n✅ Ejemplo respuestas PARCIALES:\")\n",
    "print(df_parciales.head(2))\n",
    "\n",
    "print(f\"\\nConteo por categoría:\")\n",
    "print(f\"Correctas: {len(df_correctas)}\")\n",
    "print(f\"Incorrectas: {len(df_incorrectas)}\")\n",
    "print(f\"Parciales: {len(df_parciales)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14184ab8-e893-442e-a0a5-d80571dbcc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='La capital de Francia es París (en francés, Paris).' additional_kwargs={} response_metadata={'model': 'llama3', 'created_at': '2025-09-04T14:53:45.5395206Z', 'done': True, 'done_reason': 'stop', 'total_duration': 25791428600, 'load_duration': 93460600, 'prompt_eval_count': 20, 'prompt_eval_duration': 778683300, 'eval_count': 16, 'eval_duration': 2181033900, 'model_name': 'llama3'} id='run--556f23fc-15b3-4c36-817d-e11f131ee69b-0' usage_metadata={'input_tokens': 20, 'output_tokens': 16, 'total_tokens': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[33]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(\"¿Cuál es la capital de Francia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9debf2-0210-4ed4-9a8d-988c2e07ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama y HuggingFace listos\n",
      "\n",
      "### ✅ Evaluando: CORRECTAS ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: AttributeError('HuggingFaceEmbeddings' object has no attribute 'embed_query')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resultado\n\u001b[1;32m---> 46\u001b[0m res_correctas \u001b[38;5;241m=\u001b[39m evaluar_dataset(eval_correctas, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCORRECTAS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m res_incorrectas \u001b[38;5;241m=\u001b[39m evaluar_dataset(eval_incorrectas, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINCORRECTAS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m res_parciales \u001b[38;5;241m=\u001b[39m evaluar_dataset(eval_parciales, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPARCIALES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mevaluar_dataset\u001b[1;34m(ds, nombre)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluar_dataset\u001b[39m(ds, nombre):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### ✅ Evaluando: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     resultado \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m     32\u001b[0m         ds,\n\u001b[0;32m     33\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[context_precision, context_recall, faithfulness, answer_relevancy],\n\u001b[0;32m     34\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm_wrapper,\n\u001b[0;32m     35\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     36\u001b[0m         show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 🔥 procesa de a uno\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados globales:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric, score \u001b[38;5;129;01min\u001b[39;00m resultado\u001b[38;5;241m.\u001b[39m_score_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ragas\\_analytics.py:250\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    249\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 250\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    251\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ragas\\evaluation.py:297\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[0;32m    294\u001b[0m scores: t\u001b[38;5;241m.\u001b[39mList[t\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ragas\\executor.py:213\u001b[0m, in \u001b[0;36mExecutor.results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m             nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[0;32m    211\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nest_asyncio_applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m results \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_jobs())\n\u001b[0;32m    214\u001b[0m sorted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(task)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\asyncio\\windows_events.py:445\u001b[0m, in \u001b[0;36mIocpProactor.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results:\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n\u001b[0;32m    446\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\asyncio\\windows_events.py:774\u001b[0m, in \u001b[0;36mIocpProactor._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout too big\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     status \u001b[38;5;241m=\u001b[39m _overlapped\u001b[38;5;241m.\u001b[39mGetQueuedCompletionStatus(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iocp, ms)\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    776\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import ContextPrecision, ContextRecall, Faithfulness, AnswerRelevancy\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "def convertir_a_dataset(df):\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "eval_correctas = convertir_a_dataset(df_correctas)\n",
    "eval_incorrectas = convertir_a_dataset(df_incorrectas)\n",
    "eval_parciales = convertir_a_dataset(df_parciales)\n",
    "\n",
    "OLLAMA_MODEL = \"mistral\"\n",
    "chat_llm = ChatOllama(model=OLLAMA_MODEL, temperature=0.1)\n",
    "llm_wrapper = LangchainLLMWrapper(chat_llm)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Ollama y HuggingFace listos\")\n",
    "\n",
    "context_precision = ContextPrecision()\n",
    "context_recall = ContextRecall()\n",
    "faithfulness = Faithfulness()\n",
    "answer_relevancy = AnswerRelevancy()\n",
    "\n",
    "def evaluar_dataset(ds, nombre):\n",
    "    print(f\"\\n### Evaluando: {nombre} ###\")\n",
    "    resultado = evaluate(\n",
    "        ds,\n",
    "        metrics=[context_precision, context_recall, faithfulness, answer_relevancy],\n",
    "        llm=llm_wrapper,\n",
    "        embeddings=embeddings,\n",
    "        show_progress=False,\n",
    "        batch_size=1\n",
    "    )\n",
    "\n",
    "    print(\"\\nResultados globales:\")\n",
    "    for metric, score in resultado._score_dict.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "    return resultado\n",
    "\n",
    "res_correctas = evaluar_dataset(eval_correctas, \"CORRECTAS\")\n",
    "res_incorrectas = evaluar_dataset(eval_incorrectas, \"INCORRECTAS\")\n",
    "res_parciales = evaluar_dataset(eval_parciales, \"PARCIALES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad723d30-ca5b-4fbc-84a3-c2cc834f2925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
